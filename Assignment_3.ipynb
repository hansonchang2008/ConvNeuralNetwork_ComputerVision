{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3\n",
    "Hanson, Hanxiang Zhang, 300100018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation:\n",
    "I imported the data from the files.\n",
    "There are two ways of concatenating the input start and goal images.\n",
    "Method 1:\n",
    "Concatenate the pair of start and goal images horizontally into a new image with 3 channels (Blue, Green, Red). The image size is 128 by 64. The array named train_img_rot is for training rotation dataset, train_img_mix for training mix dataset, test_img_rot for testing rotation dataset, test_img_mix for testing mix dataset. Validation is included in the training dataset.\n",
    "Method 2:\n",
    "keep the original data format, where each image pair has 6 dimensions, where the first 3 channels (Blue, Green, Red) belong to the start image and the second 3 channels belong to the goal image. The image size is 64 by 64. The array named is for train_images for training rotation dataset, train_images_mix for training mix dataset, test_images for testing rotation dataset, test_images_mix for testing mix dataset.\n",
    "Which method to choose?\n",
    "I selected method 2 after I tried many architectures and the neural network could not learn, i.e. decrease the training error and validation error when I used data prepared with method 1.\n",
    "For example, I used the same architecture with 7 conv layers with 64 neurons in each layer for both data prepared by method 1 and 2 to run the training process, and the training Mean Squared Error for method 1 data is around 0.5978 after 100 epoches, which is close to the initial MSE which is 0.61. Meanwhile the validation MSE goes up to 0.7128 from 0.58 which is quite bad. However, for method 2 data the training MSE graduately decreases and ends up with 0.0050, while the initial MSE is 0.60.\n",
    "Meanwhile, the validation MSE decreases incrementally and ends up with 0.0310, while the initial valid MSE is 0.59.\n",
    "\n",
    "And the train_flows is the optical flow for rotational training data, which has removed the last two channels because they are the negative of the first two channels respectively. Where the four channels are [flow(x); flow(y); flow(-x); flow(-y)]. Likewise for the testing rotation optical flow, named test_flows, and training and testing mixed optical flow, named train_flows_mix and test_flows_mix respectively.\n",
    "\n",
    "After importing the dataset, I shuffled the order of training data and testing data respectively using sklearn.utils.shuffle.\n",
    "\n",
    "Dataset Review:\n",
    "There are 1860 rotation image pairs for training, 444 rotation image pairs for testing.\n",
    "And there are 1860 mixed image pairs for training, 444 mixed image pairs for testing.\n",
    "Validation is in the training images. The validation rate is set to be 0.11. As a result, there are 1655 image pairs for training, and 205 for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanson\\Anaconda3\\python.exe\n",
      "C:\\Users\\hanson\\Downloads\n",
      "Size of training images: 1860 x 6 x 64 x 64\n",
      "\n",
      "Size of testing images: 444 x 6 x 64 x 64\n",
      "\n",
      "Size of training images mix: 1860 x 6 x 64 x 64\n",
      "\n",
      "Size of testing images mix: 444 x 6 x 64 x 64\n",
      "\n",
      "Size of train flow results: 1860 x 2 x 64 x 64\n",
      "\n",
      "Size of test flow results: 444 x 2 x 64 x 64\n",
      "\n",
      "TRAIN ROT Size of combined images: 1860 x 3 x 128 x 64\n",
      "\n",
      "TEST ROT Size of combined images: 444 x 3 x 128 x 64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import skimage \n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# The data directory\n",
    "dire = os.getcwd()\n",
    "print(dire)\n",
    "PROJECT_ROOT_DIR = \"C:/Users/hanson/OneDrive/Grad/CNN in CV/data/\" #Directory for image data\n",
    "\n",
    "train_images = np.load(os.path.join(PROJECT_ROOT_DIR, 'rot_images_train.npy'))\n",
    "train_flows = np.load(os.path.join(PROJECT_ROOT_DIR, 'rot_flows_train.npy'))\n",
    "train_images, train_flows = shuffle(train_images, train_flows) #Shuffle the data\n",
    "\n",
    "test_images = np.load(os.path.join(PROJECT_ROOT_DIR, 'rot_images_test.npy'))\n",
    "test_flows = np.load(os.path.join(PROJECT_ROOT_DIR, 'rot_flows_test.npy'))\n",
    "test_images, test_flows = shuffle(test_images, test_flows) #Shuffle the data\n",
    "\n",
    "train_images_mix = np.load(os.path.join(PROJECT_ROOT_DIR, 'mix_images_train.npy'))\n",
    "train_flows_mix = np.load(os.path.join(PROJECT_ROOT_DIR, 'mix_flows_train.npy'))\n",
    "train_images_mix, train_flows_mix = shuffle(train_images_mix, train_flows_mix) #Shuffle the data\n",
    "\n",
    "test_images_mix = np.load(os.path.join(PROJECT_ROOT_DIR, 'mix_images_test.npy'))\n",
    "test_flows_mix = np.load(os.path.join(PROJECT_ROOT_DIR, 'mix_flows_test.npy'))\n",
    "test_images_mix, test_flows_mix = shuffle(test_images_mix, test_flows_mix) #Shuffle the data\n",
    "\n",
    "print('Size of training images: {0} x {1} x {2} x {3}\\n'.format(*train_images.shape))\n",
    "#print('Size of flow results: {0} x {1} x {2} x {3}\\n'.format(*train_flows.shape))\n",
    "print('Size of testing images: {0} x {1} x {2} x {3}\\n'.format(*test_images.shape))\n",
    "#print('Size of flow results: {0} x {1} x {2} x {3}\\n'.format(*test_flows.shape))\n",
    "print('Size of training images mix: {0} x {1} x {2} x {3}\\n'.format(*train_images_mix.shape))\n",
    "#print('Size of flow results: {0} x {1} x {2} x {3}\\n'.format(*train_flows_mix.shape))\n",
    "print('Size of testing images mix: {0} x {1} x {2} x {3}\\n'.format(*test_images_mix.shape))\n",
    "#print('Size of flow results: {0} x {1} x {2} x {3}\\n'.format(*test_flows_mix.shape))\n",
    "train_flows=train_flows[:,:2,:,:] #slicing\n",
    "#train_flows=train_flows.reshape((-1,2,64,64))\n",
    "test_flows=test_flows[:,:2,:,:]\n",
    "train_flows_mix=train_flows_mix[:,:2,:,:]\n",
    "test_flows_mix=test_flows_mix[:,:2,:,:]\n",
    "print('Size of train flow results: {0} x {1} x {2} x {3}\\n'.format(*train_flows.shape))\n",
    "print('Size of test flow results: {0} x {1} x {2} x {3}\\n'.format(*test_flows.shape))\n",
    "##print('Size of flow results: {0} x {1} x {2} x {3}\\n'.format(*train_flows_mix.shape))\n",
    "#print('Size of flow results: {0} x {1} x {2} x {3}\\n'.format(*test_flows_mix.shape))\n",
    "\n",
    "def concatenate(images):\n",
    "    images_start=images[:,:3,:,:]\n",
    "    images_goal=images[:,3:,:,:]\n",
    " #   print('Size of start images: {0} x {1} x {2} x {3}\\n'.format(*images_start.shape))\n",
    " #   print('Size of goal images: {0} x {1} x {2} x {3}\\n'.format(*images_goal.shape))\n",
    "    con_images=np.concatenate((np.array(images_start),np.array(images_goal)), axis=2)\n",
    "#    print('Size of combined images: {0} x {1} x {2} x {3}\\n'.format(*con_images.shape))\n",
    "    return con_images\n",
    "    \n",
    "train_img_rot=concatenate(train_images);\n",
    "print('TRAIN ROT Size of combined images: {0} x {1} x {2} x {3}\\n'.format(*train_img_rot.shape))\n",
    "test_img_rot=concatenate(test_images);\n",
    "print('TEST ROT Size of combined images: {0} x {1} x {2} x {3}\\n'.format(*test_img_rot.shape))\n",
    "\n",
    "train_img_mix=concatenate(train_images_mix);\n",
    "#print('TRAIN MIX Size of combined images: {0} x {1} x {2} x {3}\\n'.format(*train_img_mix.shape))\n",
    "test_img_mix=concatenate(test_images_mix);\n",
    "#print('TEST MIX Size of combined images: {0} x {1} x {2} x {3}\\n'.format(*test_img_mix.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, the input to the network is determined to be the 6 channel images of 64 by 64, which is the original data format. This is because the other data format where image pairs are concatenated into 128 by 64 does not work for my CNN.\n",
    "\n",
    "I used 7 hidden layers to create the CNN network for regression using Sequential API. In each hidden layer, there is one convolutional layer with activation function followed. The model is shown as below.\n",
    "\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "conv2d (Conv2D)              (None, 64, 64, 64)        9664      \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 64, 64, 64)        4160      \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 64, 64, 64)        102464    \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 64, 64, 64)        36928     \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 64, 64, 64)        102464    \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 64, 64, 64)        36928     \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 64, 64, 64)        102464    \n",
    "_________________________________________________________________\n",
    "conv2d_7 (Conv2D)            (None, 2, 64, 64)         1154      \n",
    "Total params: 396,226\n",
    "Trainable params: 396,226\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "\n",
    "The number of filters is 64 for each layer. It has a filter size that is either (5, 5), (3, 3) or (1, 1). I changed some kernal size to (3, 3) but the performance seems to be similar.\n",
    "\n",
    "The activation function is Rectified Linear Unit, which is shown to perform best by my experiment. I tried Sigmoid and Tanh as well, but neither of them could make the CNN learn since MSE does not go down throughout the 100 training epoches.\n",
    "\n",
    "And the maximum pooling layer were initially followed, but finally removed because this is regression rather than classification. Max pooling in this task seems to have trivial influence on the performance.\n",
    "\n",
    "I also tried different learning rate for optimizers such as 0.005. However, the default learning rate which is 0.001 is the only learning rate that works well. Optimizers such as SGD, Adam, Nadam and Adagrad are also tried. Adam is the best and selected. While optimizer SGD makes the MSE decrease slower than Adam, but at least the MSE is decreasing for both training and validation. Optimizer Nadam does not work at all, training MSE is constantly 0.6610 and validation MSE is always about 0.5277. Optimizer Adagrad makes the MSE decrease faster in the beginning compared to later epoches. The speed of decreasing of MSE become slower along with the increase of number of epoches. This is because Adagrad use adaptive learning rate, which makes the changes sligher for parameters that are changed more frequently. As a result, the learning of CNN becomes slower than Adam optimizer.\n",
    "\n",
    "The loss function is Mean Squared Error, where Loss = square(y_true - y_pred). Because the optical flow has two channels indicating both x and y axis, based on the equation, Mean Squared Error is able to take the two components of the flow into account.\n",
    "\n",
    "The performance measurement I used is Mean Squared Error. Apparently we cannot use accuracy, recall and precision because this is a regression task. Another metrics for regression is Max Error, which is not suitable since it measures the maximum residual error. And it does not support multi-output for now. Besides, Mean absolute error should be okay for this task, but it is not selected due to the fact that it is more suitable for data where there're a bit outliers. And Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 64)        9664      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 64, 64)         1154      \n",
      "=================================================================\n",
      "Total params: 396,226\n",
      "Trainable params: 396,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.layers import Conv2D, MaxPooling2D, MaxPooling3D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "#For the RTX 2060 GPU to work in Tensorflow-gpu 2.0, setting the memory growth.\n",
    "import tensorflow.keras\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, MaxPooling3D, UpSampling3D,Conv2DTranspose, Conv3DTranspose\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same', data_format='channels_first', input_shape=(3,128,64)))\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same', data_format='channels_first', input_shape=(6,64,64)))\n",
    "#model.add(MaxPooling2D(pool_size=(2,1)))\n",
    "\n",
    "model.add(Conv2D(64, (1, 1), activation='relu', padding='same', data_format='channels_first'))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='same', data_format='channels_first'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first'))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='same', data_format='channels_first'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first'))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='same', data_format='channels_first'))\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), activation='linear', padding='same', data_format='channels_first'))\n",
    "\n",
    "sgd = tensorflow.keras.optimizers.SGD(lr=0.001)\n",
    "adam = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "nadam = tensorflow.keras.optimizers.Nadam(lr=0.001)\n",
    "adagrad = tensorflow.keras.optimizers.Adagrad(lr=0.001)\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "              optimizer='adam',\n",
    "              metrics=['mean_squared_error'])\n",
    "print(model.summary())\n",
    "\n",
    "model1=model #Copy the model for mixed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I trained it on the rotation training set. \n",
    "Because the order in dataset, the weights and biases in CNN are randomly initialized each time, there is a possibility that sometimes the MSE of the model stays at 0.6621 and does not change. If so, run the program again.\n",
    "Performance for training and validation dataset:\n",
    "The learning of CNN seems really good, the training MSE decreases gradually from 0.6145 to 0.0037 after 100 epochs, while the validation MSE decreases gradually from 0.6250 to 0.0055. Part of the training & validation result is shown below.\n",
    "\n",
    "Train on 1655 samples, validate on 205 samples\n",
    "Epoch 1/100\n",
    "1655/1655 [==============================] - 4s 3ms/sample - loss: 0.6145 - mean_squared_error: 0.6145 - val_loss: 0.6250 - val_mean_squared_error: 0.6250\n",
    "Epoch 2/100\n",
    "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5011 - mean_squared_error: 0.5011 - val_loss: 0.3734 - val_mean_squared_error: 0.3734\n",
    "...\n",
    "\n",
    "Epoch 100/100\n",
    "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0055 - val_mean_squared_error: 0.0055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1655 samples, validate on 205 samples\n",
      "Epoch 1/20\n",
      "1655/1655 [==============================] - 6s 4ms/sample - loss: 0.5355 - mean_squared_error: 0.5355 - val_loss: 0.3622 - val_mean_squared_error: 0.3622\n",
      "Epoch 2/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.2536 - mean_squared_error: 0.2536 - val_loss: 0.2057 - val_mean_squared_error: 0.2057\n",
      "Epoch 3/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.1845 - mean_squared_error: 0.1845 - val_loss: 0.1537 - val_mean_squared_error: 0.1537\n",
      "Epoch 4/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.1364 - mean_squared_error: 0.1364 - val_loss: 0.1250 - val_mean_squared_error: 0.1250\n",
      "Epoch 5/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.1083 - mean_squared_error: 0.1083 - val_loss: 0.0975 - val_mean_squared_error: 0.0975\n",
      "Epoch 6/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0878 - mean_squared_error: 0.0878 - val_loss: 0.0810 - val_mean_squared_error: 0.0810\n",
      "Epoch 7/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0742 - mean_squared_error: 0.0742 - val_loss: 0.0696 - val_mean_squared_error: 0.0696\n",
      "Epoch 8/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0603 - mean_squared_error: 0.0603 - val_loss: 0.0571 - val_mean_squared_error: 0.0571\n",
      "Epoch 9/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0520 - mean_squared_error: 0.0520 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
      "Epoch 10/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0464 - mean_squared_error: 0.0464 - val_loss: 0.0526 - val_mean_squared_error: 0.0526\n",
      "Epoch 11/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0413 - mean_squared_error: 0.0413 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
      "Epoch 12/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
      "Epoch 13/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "Epoch 14/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0284 - val_mean_squared_error: 0.0284\n",
      "Epoch 15/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
      "Epoch 16/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
      "Epoch 17/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 18/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0243 - val_mean_squared_error: 0.0243\n",
      "Epoch 19/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
      "Epoch 20/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n"
     ]
    }
   ],
   "source": [
    "batchSize = 10\n",
    "nEpochs = 20 #100\n",
    "\n",
    "#history = model.fit(train_img_rot, train_flows, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)\n",
    "history = model.fit(train_images, train_flows, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate it on the rotation test set:\n",
    "After I got the best CNN model, I finalize the model and test it on the rotation test set.\n",
    "The performance on the test set is very good, which is lower than the training set.\n",
    "Mean Squared Error for Test Set is: 0.0056, which is a bit higher than the valiadation MSE by 0.0001. And test MSE is higher than the training MSE by 0.0019.\n",
    "This is a model that shows a little bit overfitting because the model perform better for training dataset. However, because the MSE for test set is already very low and is basically equivalent to MSE for valdiation set, this model is still good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n",
      "Mean Squared Error for Test Set is: 0.0213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_flow_result = model.predict(test_images)\n",
    "#Reshape to make the flow array two dimensional so that it can use sklearn MSE function\n",
    "test_flowsa=test_flows.reshape(test_flows.shape[0],8192) #8192=2*64*64\n",
    "print(test_flows.shape[0])\n",
    "test_flow_resulta=test_flow_result.reshape(test_flows.shape[0],8192)\n",
    "\n",
    "mse=mean_squared_error(test_flowsa, test_flow_resulta)\n",
    "#msle=mean_squared_log_error(train_flowsa, train_flow_resulta)\n",
    "#Mean Squared Logarithmic Error cannot be used when targets contain negative values\n",
    "print(\"Mean Squared Error for Test Set is: %.4f\"%mse)\n",
    "#print(str(msle))\n",
    "#print(str(medae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "4. Transfer Learning\n",
    "concatenate the input start and goal images:\n",
    "In order to adapt the input to VGG16, I changed the format of the input array from 1860x6x64x64, where the six channels are [Blue1; Green1;Red1;Blue2; Green2;Red2] to 1860x128x64x3, where three channels are Red, Green and Blue.\n",
    "\n",
    "Because channels are the last dimension in data format in VGG, I changed the order of dimensions in flow data as well, from 2x64x64 to 64x64x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def concate_tl(im_ar):\n",
    "    result=np.zeros((im_ar.shape[0], 128, 64, 3))\n",
    "    #print(im_ar[66,:,13,20])\n",
    "\n",
    "    im_start=im_ar[:,:3,:,:]\n",
    "    im_start_rgb=np.zeros(im_start.shape)\n",
    "    #print(im_start_rgb.shape)\n",
    "    #print(im_start[66,:,13,20])\n",
    "    im_start_rgb[:,0,:,:]=im_start[:,2,:,:]\n",
    "    im_start_rgb[:,1,:,:]=im_start[:,1,:,:]\n",
    "    im_start_rgb[:,2,:,:]=im_start[:,0,:,:]\n",
    "    #print(im_start_rgb[66,:,13,20])\n",
    "\n",
    "    im_goal=im_ar[:,3:,:,:]\n",
    "    #print(im_goal.shape)\n",
    "    im_goal_rgb=np.zeros(im_goal.shape)\n",
    "    #print(im_goal_rgb.shape)\n",
    "    #print(im_goal[66,:,13,20])\n",
    "    im_goal_rgb[:,0,:,:]=im_goal[:,2,:,:]\n",
    "    im_goal_rgb[:,1,:,:]=im_goal[:,1,:,:]\n",
    "    im_goal_rgb[:,2,:,:]=im_goal[:,0,:,:]\n",
    "    #print(im_goal_rgb[66,:,13,20])\n",
    "    #print(im_goal.shape)\n",
    "    \n",
    "    con_image=np.concatenate((np.array(im_start_rgb),np.array(im_goal_rgb)), axis=2)\n",
    "    #print(con_image[66,:,13,20])\n",
    "    #print(con_image[66,:,13+64,20])\n",
    "    #print(con_image.shape)\n",
    "    result = np.transpose(con_image, (0, 2, 3, 1))\n",
    "    #print(result.shape)\n",
    "    #print(result[66,13,20,:])\n",
    "    #print(result[66,13+64,20,:])\n",
    "    #print(\"===================================================\")\n",
    "    return result\n",
    "    \n",
    "train_im_tl=concate_tl(train_images)\n",
    "test_im_tl=concate_tl(test_images)\n",
    "train_im_mix_tl=concate_tl(train_images_mix)\n",
    "test_im_mix_tl=concate_tl(test_images_mix)\n",
    "\n",
    "#print(train_flows[12,1,36,48])\n",
    "#for i in range(64):\n",
    "#    for j in range(64):\n",
    "#        if train_flows[12,1,i,j]!=0:\n",
    "#            print(str(i)+str(j))\n",
    "train_flows_r = np.transpose(train_flows, (0, 2, 3, 1))\n",
    "#print(train_flows_r[12,36,48, 1])\n",
    "#print(train_flows_r.shape)\n",
    "test_flows_r = np.transpose(test_flows, (0, 2, 3, 1))\n",
    "#print(test_flows_r.shape)\n",
    "\n",
    "train_flows_mix_r = np.transpose(train_flows_mix, (0, 2, 3, 1))\n",
    "#print(train_flows_mix_r.shape)\n",
    "test_flows_mix_r = np.transpose(test_flows_mix, (0, 2, 3, 1))\n",
    "#print(test_flows_mix_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developed and trained many models. The model that includes the first 2 conv layers of the VGG-16 model pre-trained on ImageNet with the VGG layers' weights fixed. One deconv layer is attached after the VGG to increase the number of neurons to meet the requirement for the output. After that, I added 6 conv layers and one regression layer as output layer.\n",
    "I tried keeping different number of VGG conv layers ranging from first 2 to all of them. And I also tried adding 0 to 6 conv layers from my customized network after that. I changed the optimizers as well including SGD, Adam and Adagrad, but Adam with learning rate 0.001 is obviously the best. Additionally, the batch size is 10. The max number of epochs for training is 100.\n",
    "I did the experiments on the rotation dataset and the mixed dataset.\n",
    "Most of the time, the training MSE stops at roughly 0.64 ish in rotation dataset. \n",
    "In a few cases, the training MSE goes down gradually to 0.2898. However, the Mean Squared Error for validation always stops at roughly 0.64ish in rotation dataset.\n",
    "\n",
    "\n",
    "\n",
    "For this question adapt\n",
    "VGG-16 pre-trained on ImageNet for the task. The pre-trained network is available from\n",
    "tf.keras.applications.vgg16. You want to suitably remove some layers (importing with\n",
    "include top=False is a good start but less layers are likely suficient and will run much faster)\n",
    "and add a regression layer (same or similar as above) at the output. You will need to train the\n",
    "new layers with the weights of the existing VGG layers fixed. Once you have a working regressor\n",
    "for the task, try to improve the \n",
    "flow results by training some layers a bit more (typically the\n",
    "higher-level) layers. Train and test your model als with the rotational and the mixed dataset. On\n",
    "which dataset does your network perform better.\n",
    "\n",
    "Here are some examples:\n",
    "The model with first 6 conv layers with all parameters fixed, followed by a deconv layer and an output layer.\n",
    "Epoch 1/100\n",
    "1655/1655 [==============================] - 4s 2ms/sample - loss: 1.3269 - mean_squared_error: 1.3269 - val_loss: 0.8023 - val_mean_squared_error: 0.8023\n",
    "Epoch 2/100\n",
    "1655/1655 [==============================] - 2s 1ms/sample - loss: 0.7129 - mean_squared_error: 0.7129 - val_loss: 0.7292 - val_mean_squared_error: 0.7292\n",
    "...\n",
    "\n",
    "Epoch 100/100\n",
    "1655/1655 [==============================] - 2s 1ms/sample - loss: 0.6328 - mean_squared_error: 0.6328 - val_loss: 0.6795 - val_mean_squared_error: 0.6795\n",
    "\n",
    "\n",
    "The model with first 9 conv layers with all parameters fixed, followed by a deconv layer, 2 conv layers with 128 neurons each and an output layer.\n",
    "Epoch 100/100\n",
    "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.2898 - mean_squared_error: 0.2898 - val_loss: 0.6389 - val_mean_squared_error: 0.6389\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 128, 64, 3)]      0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 64, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 64, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 8, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 128, 64, 3)]      0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 64, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 64, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 38,720\n",
      "Trainable params: 38,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 128, 64, 3)]      0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 64, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 64, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 32, 64)        0         \n",
      "=================================================================\n",
      "Total params: 38,720\n",
      "Trainable params: 0\n",
      "Non-trainable params: 38,720\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 128, 64, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 64, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 64, 64, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 64, 64, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 64, 64, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 64, 64, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 64, 64, 2)         1154      \n",
      "=================================================================\n",
      "Total params: 429,442\n",
      "Trainable params: 390,722\n",
      "Non-trainable params: 38,720\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, MaxPooling3D, UpSampling3D,Conv2DTranspose, Conv3DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#For the RTX 2060 GPU to work in Tensorflow-gpu 2.0, setting the memory growth.\n",
    "import tensorflow.keras\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "#USE ALL tf.keras\n",
    "tmodel = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(128, 64, 3), pooling=None)\n",
    "print(tmodel.summary())\n",
    "\n",
    "#Remove the last # layers\n",
    "num_del=15\n",
    "for i in range(num_del):\n",
    "    tmodel._layers.pop()\n",
    "\n",
    "#unfreeze the last n layers\n",
    "num_unf=0\n",
    "print(tmodel.summary())\n",
    "# Freeze all the VGG layers.\n",
    "for layer in tmodel.layers[:19-num_del-num_unf]:\n",
    "    layer.trainable = False\n",
    "print(tmodel.summary())\n",
    "\n",
    "#Use Deconv Layer to increase the number of neurons\n",
    "layer_deconv=Conv2DTranspose(64, kernel_size=(1, 1),strides=(1, 2), data_format='channels_last')\n",
    "\n",
    "#Add conv layers after VGG model\n",
    "layer_conv=tf.keras.layers.Conv2D(64, (1, 1), activation='relu', padding='same', data_format='channels_last')\n",
    "layer_conv2=tf.keras.layers.Conv2D(64, (5, 5), activation='relu', padding='same', data_format='channels_last')\n",
    "layer_conv3=tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_last')\n",
    "layer_conv4=tf.keras.layers.Conv2D(64, (5, 5), activation='relu', padding='same', data_format='channels_last')\n",
    "layer_conv5=tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_last')\n",
    "layer_conv6=tf.keras.layers.Conv2D(64, (5, 5), activation='relu', padding='same', data_format='channels_last')\n",
    "\n",
    "# creating the model with a regression output layer\n",
    "layer_reg=tf.keras.layers.Conv2D(2, (3, 3), activation='linear', padding='same', data_format='channels_last')\n",
    "#Max Pooling layer\n",
    "#layer_pool=tf.keras.layers.MaxPooling2D(pool_size=(2,1))\n",
    "\n",
    "tmodel_one_reg = tf.keras.Sequential()\n",
    "#tmodel_one_reg.build(input_shape=(128, 64, 3))\n",
    "for layer in tmodel.layers:\n",
    "    tmodel_one_reg.add(layer)\n",
    "tmodel_one_reg.add(layer_deconv)\n",
    "tmodel_one_reg.add(layer_conv)\n",
    "tmodel_one_reg.add(layer_conv2)\n",
    "tmodel_one_reg.add(layer_conv3)\n",
    "tmodel_one_reg.add(layer_conv4)\n",
    "tmodel_one_reg.add(layer_conv5)\n",
    "tmodel_one_reg.add(layer_conv6)\n",
    "tmodel_one_reg.add(layer_reg)\n",
    "#tmodel_one_reg.add(layer_pool)\n",
    "\n",
    "\n",
    "print(tmodel_one_reg.summary())\n",
    "tmodel_one_reg1=tmodel_one_reg #Create the model for mixed dataset\n",
    "\n",
    "#Optimizers\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.001)\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001)\n",
    "nadam = tf.keras.optimizers.Nadam(lr=0.001)\n",
    "adagrad = tf.keras.optimizers.Adagrad(lr=0.001)\n",
    "\n",
    "tmodel_one_reg.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "              optimizer='adam',\n",
    "              metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1655 samples, validate on 205 samples\n",
      "Epoch 1/20\n",
      "1655/1655 [==============================] - 5s 3ms/sample - loss: 0.6499 - mean_squared_error: 0.6499 - val_loss: 0.6819 - val_mean_squared_error: 0.6819\n",
      "Epoch 2/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6401 - mean_squared_error: 0.6401 - val_loss: 0.6812 - val_mean_squared_error: 0.6812\n",
      "Epoch 3/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6385 - mean_squared_error: 0.6385 - val_loss: 0.6800 - val_mean_squared_error: 0.6800\n",
      "Epoch 4/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6360 - mean_squared_error: 0.6360 - val_loss: 0.6743 - val_mean_squared_error: 0.6743\n",
      "Epoch 5/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6329 - mean_squared_error: 0.6329 - val_loss: 0.6741 - val_mean_squared_error: 0.6741\n",
      "Epoch 6/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6282 - mean_squared_error: 0.6282 - val_loss: 0.6703 - val_mean_squared_error: 0.6703\n",
      "Epoch 7/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6248 - mean_squared_error: 0.6248 - val_loss: 0.6670 - val_mean_squared_error: 0.6670\n",
      "Epoch 8/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6213 - mean_squared_error: 0.6213 - val_loss: 0.6700 - val_mean_squared_error: 0.6700\n",
      "Epoch 9/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6227 - mean_squared_error: 0.6227 - val_loss: 0.6659 - val_mean_squared_error: 0.6659\n",
      "Epoch 10/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6162 - mean_squared_error: 0.6162 - val_loss: 0.6615 - val_mean_squared_error: 0.6615\n",
      "Epoch 11/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6107 - mean_squared_error: 0.6107 - val_loss: 0.6630 - val_mean_squared_error: 0.6630\n",
      "Epoch 12/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6072 - mean_squared_error: 0.6072 - val_loss: 0.6572 - val_mean_squared_error: 0.6572\n",
      "Epoch 13/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6020 - mean_squared_error: 0.6020 - val_loss: 0.6583 - val_mean_squared_error: 0.6583\n",
      "Epoch 14/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5991 - mean_squared_error: 0.5991 - val_loss: 0.6564 - val_mean_squared_error: 0.6564\n",
      "Epoch 15/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5961 - mean_squared_error: 0.5961 - val_loss: 0.6501 - val_mean_squared_error: 0.6501\n",
      "Epoch 16/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5922 - mean_squared_error: 0.5922 - val_loss: 0.6476 - val_mean_squared_error: 0.6476\n",
      "Epoch 17/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5883 - mean_squared_error: 0.5883 - val_loss: 0.6495 - val_mean_squared_error: 0.6495\n",
      "Epoch 18/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5855 - mean_squared_error: 0.5855 - val_loss: 0.6538 - val_mean_squared_error: 0.6538\n",
      "Epoch 19/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5815 - mean_squared_error: 0.5815 - val_loss: 0.6531 - val_mean_squared_error: 0.6531\n",
      "Epoch 20/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.5783 - mean_squared_error: 0.5783 - val_loss: 0.6634 - val_mean_squared_error: 0.6634\n"
     ]
    }
   ],
   "source": [
    "batchSize = 10\n",
    "nEpochs = 20 #100\n",
    "\n",
    "#history = model.fit(train_img_rot, train_flows, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)\n",
    "history = tmodel_one_reg.fit(train_im_tl, train_flows_r, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the transfer learning model, the Mean Squared Error for Rotation Test Set is: 0.6088. While using the customized model, the MSE for test set is only 0.0056, which is significantly lower than that of TL model by 0.6032.\n",
    "Apparently the performance of this Transfer Learning model is worse than the customized model. I think the reason is that the fixed weights from VGG layers are learned to perform classification task, rather than regression task. In VGG-16, the goal is to do object identification in images. However, our task now is to find optical flows, which is the movement of the object. Neural Network is very sensitive to the hyperparameters. Add that these are two different tasks so that the parameters including weights and biases should be very different. Therefore, the weights and biases from VGG network may not be that useful for the regression task that find the optimal flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444, 64, 64, 2)\n",
      "(444, 8192)\n",
      "(444, 64, 64, 2)\n",
      "(444, 8192)\n",
      "Mean Squared Error for Test Set is: 0.6175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_flow_result = tmodel_one_reg.predict(test_im_tl)\n",
    "print(test_flows_r.shape)\n",
    "#Reshape to make the flow array two dimensional so that it can use sklearn MSE function\n",
    "test_flowsa=test_flows_r.reshape(test_flows_r.shape[0],8192) #8192=64*64*2\n",
    "print(test_flowsa.shape)\n",
    "print(test_flow_result.shape)\n",
    "test_flow_resulta=test_flow_result.reshape(test_flows_r.shape[0],8192)\n",
    "print(test_flow_resulta.shape)\n",
    "\n",
    "mse=mean_squared_error(test_flowsa, test_flow_resulta)\n",
    "#msle=mean_squared_log_error(train_flowsa, train_flow_resulta)\n",
    "#Mean Squared Logarithmic Error cannot be used when targets contain negative values\n",
    "print(\"Mean Squared Error for Test Set is: %.4f\"%mse)\n",
    "#print(str(msle))\n",
    "#print(str(medae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I used that TL model with Mixed dataset, the training MSE stops at around 0.62, while the vaidation MSE stops at 0.6086. This shows that the TL model get stuck at local minimum and could not continue learning even though I increase the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1655 samples, validate on 205 samples\n",
      "Epoch 1/6\n",
      "1655/1655 [==============================] - 5s 3ms/sample - loss: 0.6517 - mean_squared_error: 0.6517 - val_loss: 0.6085 - val_mean_squared_error: 0.6085\n",
      "Epoch 2/6\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6224 - mean_squared_error: 0.6224 - val_loss: 0.6769 - val_mean_squared_error: 0.6769\n",
      "Epoch 3/6\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6236 - mean_squared_error: 0.6236 - val_loss: 0.6086 - val_mean_squared_error: 0.6086\n",
      "Epoch 4/6\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6234 - mean_squared_error: 0.6234 - val_loss: 0.6086 - val_mean_squared_error: 0.6086\n",
      "Epoch 5/6\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6234 - mean_squared_error: 0.6234 - val_loss: 0.6086 - val_mean_squared_error: 0.6086\n",
      "Epoch 6/6\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.6234 - mean_squared_error: 0.6234 - val_loss: 0.6086 - val_mean_squared_error: 0.6086\n"
     ]
    }
   ],
   "source": [
    "batchSize = 10\n",
    "nEpochs = 6\n",
    "\n",
    "#history = model.fit(train_img_rot, train_flows, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)\n",
    "history = tmodel_one_reg1.fit(train_im_mix_tl, train_flows_mix_r, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then I tested the TL model on mixed dataset, and got the MSE of 0.5995. This is slightly lower than the model on the rotation dataset which is 0.6088. I think the reason why it does not perform as well as the customized model is that the weights from VGG are fixed but the task of VGG is classification rather than regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444, 64, 64, 2)\n",
      "(444, 8192)\n",
      "(444, 64, 64, 2)\n",
      "(444, 8192)\n",
      "Mean Squared Error for Test Set is: 0.5995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_flow_mix_result = tmodel_one_reg1.predict(test_im_mix_tl)\n",
    "print(test_flows_mix_r.shape)\n",
    "#Reshape to make the flow array two dimensional so that it can use sklearn MSE function\n",
    "test_mix_flowsa=test_flows_mix_r.reshape(test_flows_mix_r.shape[0],8192) #8192=64*64*2\n",
    "print(test_flowsa.shape)\n",
    "print(test_flow_result.shape)\n",
    "test_flow_mix_resulta=test_flow_mix_result.reshape(test_flow_mix_result.shape[0],8192)\n",
    "print(test_flow_mix_resulta.shape)\n",
    "\n",
    "mse=mean_squared_error(test_mix_flowsa, test_flow_mix_resulta)\n",
    "#msle=mean_squared_log_error(train_flowsa, train_flow_resulta)\n",
    "#Mean Squared Logarithmic Error cannot be used when targets contain negative values\n",
    "print(\"Mean Squared Error for Test Set is: %.4f\"%mse)\n",
    "#print(str(msle))\n",
    "#print(str(medae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I trained the customized model with the mixed dataset, and the training MSE is 0.0127, while the validation MSE is a bit higher, 0.0222. It can be seen that the MSE for both training and validation are decreasing gradually, which means that of I increase the number of epochs, the result could be even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1655 samples, validate on 205 samples\n",
      "Epoch 1/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0271 - val_mean_squared_error: 0.0271\n",
      "Epoch 2/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
      "Epoch 3/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "Epoch 4/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0263 - val_mean_squared_error: 0.0263\n",
      "Epoch 5/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0248 - val_mean_squared_error: 0.0248\n",
      "Epoch 6/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0237 - val_mean_squared_error: 0.0237\n",
      "Epoch 7/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 8/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
      "Epoch 9/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
      "Epoch 10/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0256 - val_mean_squared_error: 0.0256_squared_error: 0.\n",
      "Epoch 11/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 12/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
      "Epoch 13/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 14/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
      "Epoch 15/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "Epoch 16/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 17/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 18/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 19/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 20/20\n",
      "1655/1655 [==============================] - 4s 2ms/sample - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n"
     ]
    }
   ],
   "source": [
    "batchSize = 10\n",
    "nEpochs = 20 #100\n",
    "\n",
    "#history = model.fit(train_img_rot, train_flows, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)\n",
    "history = model1.fit(train_images_mix, train_flows_mix, batch_size=batchSize, epochs=nEpochs, verbose=1,validation_split=0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested the customized model on mixed dataset. The Mean Squared Error is 0.0208, which is considerably higher than the MSE on rotation dataset, 0.0056 by 0.0152. However, the customized model is apparently better than the TL model, while the MSE for TL model is as high as 0.5995. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n",
      "Mean Squared Error for Test Set is: 0.0208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_flow_mix_result = model1.predict(test_images_mix)\n",
    "#Reshape to make the flow array two dimensional so that it can use sklearn MSE function\n",
    "test_flowsa_mix=test_flows_mix.reshape(test_flows_mix.shape[0],8192) #8192=2*64*64\n",
    "print(test_flows_mix.shape[0])\n",
    "test_flow_mix_resulta=test_flow_mix_result.reshape(test_flows_mix.shape[0],8192)\n",
    "\n",
    "mse=mean_squared_error(test_flowsa_mix, test_flow_mix_resulta)\n",
    "#msle=mean_squared_log_error(train_flowsa, train_flow_resulta)\n",
    "#Mean Squared Logarithmic Error cannot be used when targets contain negative values\n",
    "print(\"Mean Squared Error for Test Set is: %.4f\"%mse)\n",
    "#print(str(msle))\n",
    "#print(str(medae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the performance of the customized model for both rotation dataset and mixed dataset are much better than the Transfer Learning model. And the performance of the customized model for rotation dataset is better than mixed dataset. In contrast, the performance of the Transfer learning model for rotation dataset is worse than mixed dataset.\n",
    "I believe the reason for the overall better performance of customized model is that the fixed weights from VGG layers are learned to perform classification task, which is different from our task now to find optical flows. Therefore, the weights and biases from VGG network may not be that useful for the regression task that find the optimal flows. As a result, the local minimum rather than the global minimum could be reached.\n",
    "And the reason for the fact that customized model performing better for rotation dataset than mixed dataset is that the problem is simpler in the rotation dataset in which the images have in-plane rotations and translations only. However, the problem is more difficult when there is a mixture of rotations, shearing and stretching combined with translations in the mixed dataset.\n",
    "Last but not the least, the weights in VGG model could be learnt to classify images, which are more complicated problems or more higher-level features. That's the reason why Transfer Learning model perform better for mixed dataset rather than rotation dataset, because the former is more difficult and more complicated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
