{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 2 of Hanson\n",
    "Legal Name Hanxiang Zhang\n",
    "Stu# 300100018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Normalized Face Image Comparison\n",
    "1.1 I wrote a function named data_preprocessing to read and process the image data.\n",
    "I downloaded the two subsets and unpacked the images in sub1to10 and sub31to40 directories relative to my jupyter notebook working path.\n",
    "To load all images, I generated a list of paths to the image files by reading the directory and file structure using the os package in python.\n",
    "I shuffled the lists of paths of training & validation images and testing images respectively to randomlize the data.\n",
    "Then I read the images, converted them to grayscale and rescaled them to 64 x 64.\n",
    "Finally, I used if-else statements to assign all the images with its labels, which is the number shown in its folder indicating which person it is.\n",
    "\n",
    "There are 460 images for training and validation, in sub1to10.\n",
    "There are 384 images for testing, in sub31to40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "\n",
    "def data_preprocessing():\n",
    "    #Get the current working directory\n",
    "    dire = os.getcwd()\n",
    "\n",
    "    path_train = dire+'\\\\sub1to10\\\\'\n",
    "    path_test = dire+'\\\\sub31to40\\\\'\n",
    "\n",
    "    #Read images for training and validation from sub1to10\n",
    "    train_files = []\n",
    "    for root, dirs, files in os.walk(path_train):\n",
    "        for file in files:\n",
    "            if '.png' in file:\n",
    "                train_files.append(os.path.join(root, file))\n",
    "\n",
    "    #Read images for testing from sub31to40\n",
    "    test_files = []\n",
    "    for root, dirs, files in os.walk(path_test):\n",
    "        for file in files:\n",
    "            if '.png' in file:\n",
    "                test_files.append(os.path.join(root, file))\n",
    "\n",
    "    #Randomly Shuffle the training image files and testing image files respectively\n",
    "    random.shuffle(train_files)\n",
    "    random.shuffle(test_files)\n",
    "\n",
    "    #print(len(train_files))\n",
    "    #print(len(test_files))\n",
    "\n",
    "    #Read and processing image data, and assign their corresponding labels\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "\n",
    "    #For training and validation data\n",
    "    #Read every images, convert them into grayscale images, and rescale them to 64 by 64\n",
    "    #Then add each image for training into train_images list,\n",
    "    #together with its label into train_labels list;\n",
    "    #And add each image for testing into test_images list,\n",
    "    #together with its label into test_labels list.\n",
    "    for (i, imgpath) in enumerate(train_files):#training files\n",
    "        img = skimage.io.imread(imgpath)\n",
    "        imgg = skimage.color.rgb2gray(img)\n",
    "        imgu = skimage.transform.resize(imgg, (64,64)) #resize image to 64x64\n",
    "        #if i==1:\n",
    "        #   print(imgu)\n",
    "        train_images.append(imgu)\n",
    "        lb=-1\n",
    "        if \"sub1_\" in imgpath:\n",
    "            lb=1\n",
    "        elif \"sub2_\" in imgpath:\n",
    "            lb=2\n",
    "        elif \"sub3_\" in imgpath:\n",
    "            lb=3\n",
    "        elif \"sub4_\" in imgpath:\n",
    "            lb=4\n",
    "        elif \"sub5_\" in imgpath:\n",
    "            lb=5\n",
    "        elif \"sub6_\" in imgpath:\n",
    "            lb=6\n",
    "        elif \"sub7_\" in imgpath:\n",
    "            lb=7\n",
    "        elif \"sub8_\" in imgpath:\n",
    "            lb=8\n",
    "        elif \"sub9_\" in imgpath:\n",
    "            lb=9\n",
    "        elif \"sub10_\" in imgpath:\n",
    "            lb=10\n",
    "        else:\n",
    "            lb=-1\n",
    "            print(\"Something wrong going on when labelling training data\")\n",
    "        train_labels.append(lb)\n",
    "\n",
    "    #For testing data, the same as above\n",
    "    for (i, imgpath) in enumerate(test_files):\n",
    "        img = skimage.io.imread(imgpath)\n",
    "        imgg = skimage.color.rgb2gray(img)\n",
    "        imgu = skimage.transform.resize(imgg, (64,64))\n",
    "        test_images.append(imgu)\n",
    "        lb=-1\n",
    "        if \"sub31_\" in imgpath:\n",
    "            lb=31\n",
    "        elif \"sub32_\" in imgpath:\n",
    "            lb=32\n",
    "        elif \"sub33_\" in imgpath:\n",
    "            lb=33\n",
    "        elif \"sub34_\" in imgpath:\n",
    "            lb=34\n",
    "        elif \"sub35_\" in imgpath:\n",
    "            lb=35\n",
    "        elif \"sub36_\" in imgpath:\n",
    "            lb=36\n",
    "        elif \"sub37_\" in imgpath:\n",
    "            lb=37\n",
    "        elif \"sub38_\" in imgpath:\n",
    "            lb=38\n",
    "        elif \"sub39_\" in imgpath:\n",
    "            lb=39\n",
    "        elif \"sub40_\" in imgpath:\n",
    "            lb=40\n",
    "        else:\n",
    "            lb=-1\n",
    "            print(\"Something wrong going on when labelling testing data\")\n",
    "        test_labels.append(lb)\n",
    "    print(\"Image preprocessing finished.\")\n",
    "    #print(train_images)\n",
    "    #print(test_images)\n",
    "    #print(train_labels)\n",
    "    #print(len(train_labels))\n",
    "    #print(len(test_labels))\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "#Run the function\n",
    "train_images, train_labels, test_images, test_labels=data_preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2\tTemplate Matching [2.5]\n",
    "Write a function that accepts two of the images and calculates a score based on the similarity of the two images using either cross-correlation, convolution or sum of squared differences. Choose your method carefully and perform any processing step necessary. Given the similarity score, perform a simple classification using a threshold to decide if two images show the same face. Evaluate your classifier with pairs chosen from the 460 images in the training data set. There are a total of  111 pairs but most of the pairs will show different faces. A small validation set of 1,000 pairs of images seems therefore reasonable.\n",
    "\n",
    "1.2 Template Matching\n",
    "I wrote a function named generate_pairs to generate image pairs and template_matching for this task of template matching.\n",
    "\n",
    "First of all, this accept images and generate pairs of 2 non-duplicate images. The pairs are generated by using a nested loop with i_list and j_list. The indeces of pairs are stored in i_list and j_list. The index stored in i_list corresponds to the index in j_list in the same position. For example, for the pair (0,1), 0 is in the first postion in i_list and 1 is in the first position in j_list. The pairs generated are still random even though I make the index in order because I have shuffled the dataset beforehead when I get the image path list.\n",
    "\n",
    "The number of pairs for training and validation should be 105570=(460*459)/2 in total. And the number of pairs for training is 104570, while the number of pairs for validation is 1000. I made the last 1000 image pairs as the validation. This is ok since data has been shuffled previously.\n",
    "\n",
    "The number of pairs for testing is 73536=(384*383)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105570\n",
      "105570\n",
      "105570\n",
      "104570\n",
      "104570\n",
      "1000\n",
      "1000\n",
      "Image pair generation Finished\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "from skimage.feature import match_template\n",
    "import numpy as np\n",
    "\n",
    "def generate_pairs():\n",
    "    #For training and validation image pairs,\n",
    "    #Generate the pairs of 2 images from the 460 images.\n",
    "    i_list=[]\n",
    "    j_list=[]\n",
    "    counter=0\n",
    "    #Generate the indices of image pairs using nested loop.\n",
    "    #I shuffled the dataset before, so I can make the numbers in order\n",
    "    for i in range(0,460):\n",
    "        for j in range(i+1,460):\n",
    "            i_list.append(i)\n",
    "            j_list.append(j)\n",
    "            counter=counter+1\n",
    "    print(counter)\n",
    "    print(len(i_list))\n",
    "    print(len(j_list))\n",
    "\n",
    "    #Divide the training and validation dataset.\n",
    "    #I shuffled the dataset before, so I can simply use the last 1000 pairs as validation pairs\n",
    "    train_i_list=i_list[:104570]\n",
    "    train_j_list=j_list[:104570]\n",
    "\n",
    "    valid_i_list=i_list[104570:]\n",
    "    valid_j_list=j_list[104570:]\n",
    "    print(len(train_i_list))\n",
    "    print(len(train_j_list))\n",
    "    print(len(valid_i_list))\n",
    "    print(len(valid_j_list))\n",
    "\n",
    "    \n",
    "    #For testing image pairs,\n",
    "    #Generate the pairs of 2 images from the 384 images.\n",
    "    test_i_list=[]\n",
    "    test_j_list=[]\n",
    "    counter_t=0\n",
    "    #I shuffled the dataset before, so I can make the numbers in order\n",
    "    for i in range(0,384):\n",
    "        for j in range(i+1,384):\n",
    "            test_i_list.append(i)\n",
    "            test_j_list.append(j)\n",
    "            counter_t=counter_t+1\n",
    "    print(\"Image pair generation Finished\")\n",
    "    return train_i_list, train_j_list, valid_i_list, valid_j_list, test_i_list, test_j_list\n",
    "    \n",
    "train_i_list, train_j_list, valid_i_list, valid_j_list, test_i_list, test_j_list=generate_pairs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the indices of pairs of images are generated, I calculate the similarity score using cross-correlation. This is achieved by using match_template in skimage. It uses a Fast Normalized Cross-Correlation approach by J. P. Lewis which employs tables that have integrals of two images that are obtained previously for normalization with reduced computing time [1].\n",
    "The score ranges from -1 to 1, which is correlation coefficient. while here most of the them are from 0 to 1. A higher score indicates a higher similarity.\n",
    "\n",
    "I tried the threshold values of 0.7, 0.75, 0.8, 0.85, 0.9 and got the results shown below. The images being classified as the same person is the positive class. The accuracy seem high for all the threshold values, but this is because we have skewed dataset. Most image pairs are of different people. Hence, showing the same people is the minority class. For this reason, it is important to check the recall and precision. As you can see, the recall rate is higher than precision for threshold 0.7 by about 30%. And for threshold value 0.8, 0.85 and 0.9, the precision is higher than the recall, and the difference between recall and precision increases when the threshold value increases, and precision is higher. This means for these thresholds, the classifier lean to either positive or negative side. For threshold value 0.75, there is a slight difference between recall and precision, which shows a good balance between recall and precision when they are both higher than 0.7. That's why I choose 0.75 as the threshold to use on the testing dataset.\n",
    "\n",
    "Threshold 0.7\n",
    "Training accuracy is:0.9128430716266616\n",
    "Training recall is:0.816153546375682\n",
    "Training precision is:0.536849525762625\n",
    "Confusion matrix \n",
    " [8377 7227 ]\n",
    "[1887 87079]\n",
    "\n",
    "Validation accuracy is:0.93\n",
    "Validation recall is:0.8488372093023255\n",
    "Validation precision is0.5615384615384615\n",
    "Confusion matrix \n",
    " [73 57 ]\n",
    "[13 857]\n",
    "\n",
    "\n",
    "Threshold 0.75\n",
    "Training accuracy is:0.9444008797934398\n",
    "Training recall is:0.7422057677318784\n",
    "Training precision is:0.7062859262006305\n",
    "Confusion matrix \n",
    " [7618 3168 ]\n",
    "[2646 91138]\n",
    "\n",
    "Validation accuracy is:0.958\n",
    "Validation recall is:0.7906976744186046\n",
    "Validation precision is0.7391304347826086\n",
    "Confusion matrix \n",
    " [68 24 ]\n",
    "[18 890]\n",
    "\n",
    "\n",
    "Threshold 0.8\n",
    "Training accuracy is:0.9549297121545376\n",
    "Training recall is:0.6457521434138738\n",
    "Training precision is:0.8602206359506813\n",
    "Confusion matrix \n",
    " [6628 1077 ]\n",
    "[3636 93229]\n",
    "\n",
    "Validation accuracy is:0.969\n",
    "Validation recall is:0.7209302325581395\n",
    "Validation precision is0.8985507246376812\n",
    "Confusion matrix \n",
    " [62 7 ]\n",
    "[24 907]\n",
    "\n",
    "\n",
    "Threshold 0.85\n",
    "Training accuracy is:0.9511714640910395\n",
    "Training recall is:0.5222135619641465\n",
    "Training precision is:0.9636821287306724\n",
    "Confusion matrix \n",
    " [5360 202 ]\n",
    "[4904 94104]\n",
    "\n",
    "Validation accuracy is:0.962\n",
    "Validation recall is:0.5813953488372093\n",
    "Validation precision is0.9615384615384616\n",
    "Confusion matrix \n",
    " [50 2 ]\n",
    "[36 912]\n",
    "\n",
    "\n",
    "Threshold 0.9\n",
    "Training accuracy is:0.9382231997704886\n",
    "Training recall is:0.3706157443491816\n",
    "Training precision is:1.0\n",
    "Confusion matrix \n",
    " [3804 0 ]\n",
    "[6460 94306]\n",
    "\n",
    "Validation accuracy is:0.944\n",
    "Validation recall is:0.3488372093023256\n",
    "Validation precision is1.0\n",
    "Confusion matrix \n",
    " [30 0 ]\n",
    "[56 914]\n",
    "\n",
    "\n",
    "[1] J. P. Lewis, “Fast Normalized Cross-Correlation”, Industrial Light and Magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "5001\n",
      "6001\n",
      "7001\n",
      "8001\n",
      "9001\n",
      "10001\n",
      "11001\n",
      "12001\n",
      "13001\n",
      "14001\n",
      "15001\n",
      "16001\n",
      "17001\n",
      "18001\n",
      "19001\n",
      "20001\n",
      "21001\n",
      "22001\n",
      "23001\n",
      "24001\n",
      "25001\n",
      "26001\n",
      "27001\n",
      "28001\n",
      "29001\n",
      "30001\n",
      "31001\n",
      "32001\n",
      "33001\n",
      "34001\n",
      "35001\n",
      "36001\n",
      "37001\n",
      "38001\n",
      "39001\n",
      "40001\n",
      "41001\n",
      "42001\n",
      "43001\n",
      "44001\n",
      "45001\n",
      "46001\n",
      "47001\n",
      "48001\n",
      "49001\n",
      "50001\n",
      "51001\n",
      "52001\n",
      "53001\n",
      "54001\n",
      "55001\n",
      "56001\n",
      "57001\n",
      "58001\n",
      "59001\n",
      "60001\n",
      "61001\n",
      "62001\n",
      "63001\n",
      "64001\n",
      "65001\n",
      "66001\n",
      "67001\n",
      "68001\n",
      "69001\n",
      "70001\n",
      "71001\n",
      "72001\n",
      "73001\n",
      "74001\n",
      "75001\n",
      "76001\n",
      "77001\n",
      "78001\n",
      "79001\n",
      "80001\n",
      "81001\n",
      "82001\n",
      "83001\n",
      "84001\n",
      "85001\n",
      "86001\n",
      "87001\n",
      "88001\n",
      "89001\n",
      "90001\n",
      "91001\n",
      "92001\n",
      "93001\n",
      "94001\n",
      "95001\n",
      "96001\n",
      "97001\n",
      "98001\n",
      "99001\n",
      "100001\n",
      "101001\n",
      "102001\n",
      "103001\n",
      "104001\n",
      "8377\n",
      "87079\n",
      "7227\n",
      "1887\n",
      "Training accuracy is:0.9128430716266616\n",
      "Training recall is:0.816153546375682\n",
      "Training precision is:0.536849525762625\n",
      "Confusion matrix \n",
      " [8377 7227 ]\n",
      "[1887 87079]\n",
      "73\n",
      "857\n",
      "57\n",
      "13\n",
      "Validation accuracy is:0.93\n",
      "Validation recall is:0.8488372093023255\n",
      "Validation precision is0.5615384615384615\n",
      "Confusion matrix \n",
      " [73 57 ]\n",
      "[13 857]\n"
     ]
    }
   ],
   "source": [
    "def template_matching():\n",
    "    #Repeatedly get the two images in a pair, and calculate the similarity score\n",
    "    threshold=0.75\n",
    "\n",
    "    #For training dataset    \n",
    "    correct_predicted_same = 0 #TP\n",
    "    correct_predicted_diff = 0 #TN\n",
    "    wrongly_predicted_same = 0 #FP\n",
    "    wrongly_predicted_diff = 0 #FN\n",
    "    ##For 1.3, combining images\n",
    "    #train_im_combined=[]\n",
    "    #train_lb_combined=[]\n",
    "    for num in range(0,104570):#104570 for training set\n",
    "        if (num%1000 == 1):\n",
    "            print(num)\n",
    "        i=train_i_list[num]\n",
    "        j=train_j_list[num]\n",
    "    \n",
    "        co_im1=train_images[i]\n",
    "        lb_im1=train_labels[i]\n",
    "    \n",
    "        co_im2=train_images[j]\n",
    "        lb_im2=train_labels[j]   \n",
    "    \n",
    "        result = match_template(co_im1, co_im2)\n",
    "\n",
    "        if result>threshold:\n",
    "            if lb_im1 == lb_im2:\n",
    "                correct_predicted_same=correct_predicted_same+1\n",
    "            else:\n",
    "                wrongly_predicted_same=wrongly_predicted_same+1\n",
    "        else:\n",
    "            if lb_im1 != lb_im2:\n",
    "                correct_predicted_diff=correct_predicted_diff+1\n",
    "            else:\n",
    "                wrongly_predicted_diff=wrongly_predicted_diff+1\n",
    "            \n",
    "    print(correct_predicted_same)\n",
    "    print(correct_predicted_diff)\n",
    "    print(wrongly_predicted_same)\n",
    "    print(wrongly_predicted_diff)\n",
    "    accuracy=(correct_predicted_same+correct_predicted_diff)/(correct_predicted_same+correct_predicted_diff+wrongly_predicted_same+wrongly_predicted_diff)\n",
    "    recall=(correct_predicted_same)/(correct_predicted_same+wrongly_predicted_diff) #Assume the same pair is the positive\n",
    "    precision=(correct_predicted_same)/(correct_predicted_same+wrongly_predicted_same)\n",
    "    print(\"Training accuracy is:\"+str(accuracy))\n",
    "    print(\"Training recall is:\"+str(recall))\n",
    "    print(\"Training precision is:\"+str(precision))\n",
    "    print(\"Confusion matrix \\n [\"+str(correct_predicted_same)+\" \"+str(wrongly_predicted_same)+\" ]\\n\"+\"[\"+str(wrongly_predicted_diff)+\" \"+str(correct_predicted_diff)+\"]\")\n",
    "\n",
    "    \n",
    "    #For validation dataset\n",
    "    correct_predicted_same = 0 #TP\n",
    "    correct_predicted_diff = 0 #TN\n",
    "    wrongly_predicted_same = 0 #FP\n",
    "    wrongly_predicted_diff = 0 #FN\n",
    "\n",
    "    for num in range(0,1000):#1000 for validation set\n",
    "        i=valid_i_list[num]\n",
    "        j=valid_j_list[num]\n",
    "    \n",
    "        co_im1=train_images[i]\n",
    "        lb_im1=train_labels[i]\n",
    "    \n",
    "        co_im2=train_images[j]\n",
    "        lb_im2=train_labels[j]\n",
    "        \n",
    "        result = match_template(co_im1, co_im2)\n",
    "        if result>threshold:\n",
    "            if lb_im1 == lb_im2:\n",
    "                correct_predicted_same=correct_predicted_same+1\n",
    "            else:\n",
    "                wrongly_predicted_same=wrongly_predicted_same+1\n",
    "        else:\n",
    "            if lb_im1 != lb_im2:\n",
    "                correct_predicted_diff=correct_predicted_diff+1\n",
    "            else:\n",
    "                wrongly_predicted_diff=wrongly_predicted_diff+1\n",
    "\n",
    "    print(correct_predicted_same)\n",
    "    print(correct_predicted_diff)\n",
    "    print(wrongly_predicted_same)\n",
    "    print(wrongly_predicted_diff)\n",
    "    accuracy=(correct_predicted_same+correct_predicted_diff)/(correct_predicted_same+correct_predicted_diff+wrongly_predicted_same+wrongly_predicted_diff)\n",
    "    recall=(correct_predicted_same)/(correct_predicted_same+wrongly_predicted_diff) #Assume the same pair is the positive\n",
    "    precision=(correct_predicted_same)/(correct_predicted_same+wrongly_predicted_same)\n",
    "    print(\"Validation accuracy is:\"+str(accuracy))\n",
    "    print(\"Validation recall is:\"+str(recall))\n",
    "    print(\"Validation precision is\"+str(precision))\n",
    "    print(\"Confusion matrix \\n [\"+str(correct_predicted_same)+\" \"+str(wrongly_predicted_same)+\" ]\\n\"+\"[\"+str(wrongly_predicted_diff)+\" \"+str(correct_predicted_diff)+\"]\")\n",
    "\n",
    "template_matching()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Perceptron\n",
    "First of all, I concatenated each image pairs into an image of 128 by 64. Meanwhile I label the concatenated images as 0 when they are the same person, as 1 when they are different persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104570\n",
      "104570\n",
      "1000\n",
      "1000\n",
      "73536\n",
      "73536\n"
     ]
    }
   ],
   "source": [
    "train_im_combined=[]\n",
    "train_lb_combined=[]\n",
    "for num in range(0,104570):#104570 for training set\n",
    "    i=train_i_list[num]\n",
    "    j=train_j_list[num]\n",
    "    \n",
    "    co_im1=train_images[i]\n",
    "    lb_im1=train_labels[i]\n",
    "\n",
    "    co_im2=train_images[j]\n",
    "    lb_im2=train_labels[j]\n",
    "    #Concatenate Images and label them  \n",
    "    combined_image = np.concatenate((co_im1,co_im2),axis=1)\n",
    "    combined_image_f=combined_image.flatten()\n",
    "    train_im_combined.append(combined_image_f)\n",
    "    if lb_im1 == lb_im2:\n",
    "        train_lb_combined.append(0);\n",
    "    else:\n",
    "        train_lb_combined.append(1);\n",
    "print(len(train_im_combined))\n",
    "print(len(train_lb_combined))\n",
    "\n",
    "#For validation dataset\n",
    "##For 1.3, combining images\n",
    "valid_im_combined=[]\n",
    "valid_lb_combined=[]\n",
    "for num in range(0,1000):#1000 for validation set\n",
    "    i=valid_i_list[num]\n",
    "    j=valid_j_list[num]\n",
    "    \n",
    "    co_im1=train_images[i]\n",
    "    lb_im1=train_labels[i]\n",
    "    \n",
    "    co_im2=train_images[j]\n",
    "    lb_im2=train_labels[j]\n",
    "    #Concatenate Images and label them  \n",
    "    combined_image = np.concatenate((co_im1,co_im2),axis=1)\n",
    "    combined_image_f=combined_image.flatten()\n",
    "    valid_im_combined.append(combined_image_f)\n",
    "    if lb_im1 == lb_im2:\n",
    "        valid_lb_combined.append(0);\n",
    "    else:\n",
    "        valid_lb_combined.append(1);\n",
    "print(len(valid_im_combined))\n",
    "print(len(valid_lb_combined))\n",
    "\n",
    "test_im_combined = []\n",
    "test_lb_combined = []\n",
    "for num in range(0, 73536):  # 73536 for testing set\n",
    "    i = test_i_list[num]\n",
    "    j = test_j_list[num]\n",
    "\n",
    "    co_im1 = test_images[i]\n",
    "    lb_im1 = test_labels[i]\n",
    "\n",
    "    co_im2 = test_images[j]\n",
    "    lb_im2 = test_labels[j]\n",
    "    # Concatenate Images and label them\n",
    "    combined_image = np.concatenate((co_im1, co_im2), axis=1)\n",
    "    combined_image_f = combined_image.flatten()\n",
    "    test_im_combined.append(combined_image_f)\n",
    "    if lb_im1 == lb_im2:\n",
    "        test_lb_combined.append(0);\n",
    "    else:\n",
    "        test_lb_combined.append(1);\n",
    "print(len(test_im_combined))\n",
    "print(len(test_lb_combined))\n",
    "\n",
    "train_im_combined=np.array(train_im_combined)\n",
    "train_lb_combined=np.array(train_lb_combined)\n",
    "valid_im_combined=np.array(valid_im_combined)\n",
    "valid_lb_combined=np.array(valid_lb_combined)\n",
    "test_im_combined=np.array(test_im_combined)\n",
    "test_lb_combined=np.array(test_lb_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I built and trained a multi-layer perceptron using Keras in Python. Initially I intended to use MLP function in sklearn. but my laptop cannot run it due to memory error, because of the limit of my laptop RAM. Then I switched to Keras and it worked.\n",
    "\n",
    "I fit the training data (104570) into the model, and use validation data (1000) to get accuracy, recall, precision and confusion matrix to review and modify the network architecture. Finally I decided my model has two hidden layers, each of them has 50 neurons. This is because this model perform best among all the models I tried, in terms of precision and recall mainly. This is because our data is imblanced, and label 0 is the minority class so that accuracy is not that useful here. Some other models I tried are listed below for comparison.\n",
    "As you can see, the 50 by 50 model is the best. The precison and recall are all very high. And the confusion matrix is the best among the followings.\n",
    "And have a look at confusion matrix, you will find that for 1 layer with 30 neurons there is no true positives, which means the model simply predict all the input into being different persons, which is the majority class. This is because most of our data samples are being different persons, so that the classifier just predict as the majority which is wrong. I think this is because the model is too simple. That's why I increase the number of layers to two, and three as you can see.\n",
    "\n",
    "The activation layers are Rectified Linear Unit for hidden layers. For output layer, the activation function is sigmoid because this is a binary classification.\n",
    "\n",
    "Optimizer is Adam Optimizer, which is most popular now.\n",
    "\n",
    "I changed loss function to binary_crossentropy once, and I changed epochs to 2 and 5. However, these changes do not make a visible change on the output.\n",
    "\n",
    "\n",
    "2 hidden layers, 50 by 50 neurons\n",
    "104570/104570 [==============================] - 176s 2ms/step - loss: 0.0669 - accuracy: 0.9151\n",
    "Valid accuracy: 98.1000000000%\n",
    "Valid precision:98.7709497207%\n",
    "Valid recall:99.1031390135%\n",
    "Valid confusion matrix is:\n",
    "[[ 97  11]\n",
    " [  8 884]]\n",
    "\n",
    "\n",
    "1 hidden layer with 30 neurons\n",
    "Valid accuracy: 90.5000000000%\n",
    "Valid precision:90.5000000000%\n",
    "Valid recall:100.0000000000%\n",
    "Valid confusion matrix is:\n",
    "[[  0  95]\n",
    " [  0 905]]\n",
    "\n",
    "\n",
    "2 hidden layers, 30 by 10 neurons\n",
    "Valid accuracy: 90.9000000000%\n",
    "Valid precision:91.2032355915%\n",
    "Valid recall:99.5584988962%\n",
    "Valid confusion matrix is:\n",
    "[[  7  87]\n",
    " [  4 902]]\n",
    "\n",
    "3 hidden layesr, 90 by 60 by 30\n",
    "Valid accuracy: 92.6000000000%\n",
    "Valid precision:97.8235967927%\n",
    "Valid recall:93.9493949395%\n",
    "Valid confusion matrix is:\n",
    "[[ 72  19]\n",
    " [ 55 854]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104570/104570 [==============================] - 159s 2ms/step - loss: 0.0690 - accuracy: 0.9112\n",
      "model fitted\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlp = Sequential()\n",
    "\n",
    "from keras.layers import Dense\n",
    "mlp.add(Dense(units=50, input_shape=(8192,), activation='relu')) #8192 is the nodes in the input layer, which is the number of pixels 128*64\n",
    "mlp.add(Dense(units=50, activation='relu'))\n",
    "mlp.add(Dense(units=1, activation='sigmoid')) #output layer\n",
    "\n",
    "mlp.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "mlp.fit(train_im_combined, train_lb_combined, epochs=1, batch_size=32)\n",
    "print(\"model fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy: 93.6000000000%\n",
      "Valid precision:93.4426229508%\n",
      "Valid recall:100.0000000000%\n",
      "Valid confusion matrix is:\n",
      "[[ 24  64]\n",
      " [  0 912]]\n",
      "1000/1000 [==============================] - 0s 184us/step\n",
      "[0.037875514088198545, 0.9359999895095825]\n"
     ]
    }
   ],
   "source": [
    "valid_pdlb_combined = mlp.predict_classes(valid_im_combined)\n",
    "#print(valid_pdlb_combined)\n",
    "valid_accuracy = accuracy_score(valid_lb_combined, valid_pdlb_combined)\n",
    "print(\"Valid accuracy: {:.10f}%\".format(valid_accuracy * 100))\n",
    "valid_precision = precision_score(valid_lb_combined, valid_pdlb_combined)\n",
    "print(\"Valid precision:{:.10f}%\".format(valid_precision * 100))\n",
    "valid_recall = recall_score(valid_lb_combined, valid_pdlb_combined)\n",
    "print(\"Valid recall:{:.10f}%\".format(valid_recall * 100))\n",
    "valid_confu_matrix = confusion_matrix(valid_lb_combined,valid_pdlb_combined)\n",
    "print(\"Valid confusion matrix is:\")\n",
    "print(valid_confu_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Classification Comparison\n",
    "I use threshold 0.75 for template matching model, and use 50 by 50 hidden layers for MLP model. The result of testing are shown below.\n",
    "\n",
    "For Template Matching:\n",
    "Testing accuracy is: 91.58235422106179% (0.9158235422106179)\n",
    "Testing recall is: 80.25568181818182% (0.8025568181818182)\n",
    "Testing precision is 59.98938241019288% (0.5998938241019288)\n",
    "Confusion matrix \n",
    " [6780 4522 ]\n",
    "[1668 60566]\n",
    "\n",
    "For MLP:\n",
    "Test accuracy: 81.6430047868%\n",
    "Test recall:83.5345993117%\n",
    "Test precision:95.1323640054%\n",
    "Test confusion matrix is:\n",
    "[[ 5666  2782]\n",
    " [10717 54371]]\n",
    "\n",
    "If we look at accuracy, Template Matching has an accuracy higher than MLP by about 10%. But accuracy may not be a good indicator for performance because in the dataset, there are much more negatives than positives. If the classifier simply predict all the testing data samples as Negative(i.e. different persons), the accuarcy will be (Negative samples/All the samples), which looks really high which is 77.72%=57153/73536. However, the performance is bad apparently.\n",
    "\n",
    "Therefore, we need to compare recall and precision. Recall is the percentage of true positive sample in all the real positive samples. And precision is the percentage of true positive sample in the predicted positive results. In terms of them, it is obvious that MLP perform better than Template Matching. In particular, the precision of MLP is 36% higher than Template Matching. Therefore, I prefer the Multi-layer Perceptron in terms of performance because of the imbalanced situation of our dataset.\n",
    "\n",
    "In terms of training effort, the building and the training process for Multi-layer Perceptron model is about 6 mins.The MLP I used has 50*50=2500 connections which requires some computation resources. And the image processing takes a bit more time for Multi-layer Perceptron because we need to concatenate the image pairs. In contrast, Template Matching does not have explicit training process, or model building process. And the image pairs do not need to be concatenated. Therefore, for training effort, I think template matching is better.\n",
    "\n",
    "About prediction speed, the template matching takes about 6 seconds per 1000 samples. However, the Multi-layer Perceptron takes about 1 second per 1000 samples. MLP is faster than template matching for prediction.\n",
    "\n",
    "For generalization, I think the MLP would be better because the MLP has a higher complexity compared to template matching. The MLP I used has 50*50=2500 connections in the hidden layers. And based on recall and precision, MLP generalize better for unseen data than template matching.\n",
    "\n",
    "For robostness, I believe that MLP is better because it is a more complex model than the template matching model. Template matching method compute the cross correlation of two images, which is prone to shift and noise in image. Therefore, MLP will be less prone to the shift and noise of the images because the model constructed is not simply calculating cross correlation between two images.\n",
    "\n",
    "Last but not the least, in terms of explainability, Template Matching is better because we have no idea what is the meaning of the learned weight and biases in multi-layer perceptron. For template matching, we know that what we got is the cross correlation which shows the similarity of two images, which outputs a correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6780\n",
      "60566\n",
      "4522\n",
      "1668\n",
      "Testing accuracy is:0.9158235422106179\n",
      "Testing recall is:0.8025568181818182\n",
      "Testing precision is0.5998938241019288\n",
      "Confusion matrix \n",
      " [6780 4522 ]\n",
      "[1668 60566]\n"
     ]
    }
   ],
   "source": [
    "#testing for template matching model\n",
    "def template_matching_testing():\n",
    "    threshold=0.75\n",
    "    #For testing dataset\n",
    "    correct_predicted_same = 0 #TP\n",
    "    correct_predicted_diff = 0 #TN\n",
    "    wrongly_predicted_same = 0 #FP\n",
    "    wrongly_predicted_diff = 0 #FN\n",
    "\n",
    "    for num in range(0,73536):#73536 for testing set\n",
    "        i=test_i_list[num]\n",
    "        j=test_j_list[num]\n",
    "    \n",
    "        co_im1=test_images[i]\n",
    "        lb_im1=test_labels[i]\n",
    "    \n",
    "        co_im2=test_images[j]\n",
    "        lb_im2=test_labels[j]\n",
    "    \n",
    "        result = match_template(co_im1, co_im2)\n",
    "        if result>threshold:\n",
    "            if lb_im1 == lb_im2:\n",
    "                correct_predicted_same=correct_predicted_same+1\n",
    "            else:\n",
    "                wrongly_predicted_same=wrongly_predicted_same+1\n",
    "        else:\n",
    "            if lb_im1 != lb_im2:\n",
    "                correct_predicted_diff=correct_predicted_diff+1\n",
    "            else:\n",
    "                wrongly_predicted_diff=wrongly_predicted_diff+1\n",
    "\n",
    "    print(correct_predicted_same)\n",
    "    print(correct_predicted_diff)\n",
    "    print(wrongly_predicted_same)\n",
    "    print(wrongly_predicted_diff)\n",
    "    accuracy=(correct_predicted_same+correct_predicted_diff)/(correct_predicted_same+correct_predicted_diff+wrongly_predicted_same+wrongly_predicted_diff)\n",
    "    recall=(correct_predicted_same)/(correct_predicted_same+wrongly_predicted_diff) #Assume the same pair is the positive\n",
    "    precision=(correct_predicted_same)/(correct_predicted_same+wrongly_predicted_same)\n",
    "    print(\"Testing accuracy is:\"+str(accuracy))\n",
    "    print(\"Testing recall is:\"+str(recall))\n",
    "    print(\"Testing precision is\"+str(precision))\n",
    "    print(\"Confusion matrix \\n [\"+str(correct_predicted_same)+\" \"+str(wrongly_predicted_same)+\" ]\\n\"+\"[\"+str(wrongly_predicted_diff)+\" \"+str(correct_predicted_diff)+\"]\")\n",
    "\n",
    "template_matching_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Test accuracy: 88.6151000870%\n",
      "Test precision:88.6654304491%\n",
      "Test recall:99.9093534907%\n",
      "Test confusion matrix is:\n",
      "[[  135  8313]\n",
      " [   59 65029]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-da6960f5885f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_confu_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mloss_and_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_im_combined\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_lb_combined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_and_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#testing for MLP model\n",
    "\n",
    "test_pdlb_combined = mlp.predict_classes(test_im_combined)\n",
    "print(test_pdlb_combined)\n",
    "test_accuracy = accuracy_score(test_lb_combined, test_pdlb_combined)\n",
    "print(\"Test accuracy: {:.10f}%\".format(test_accuracy * 100))\n",
    "test_precision = precision_score(test_lb_combined, test_pdlb_combined)\n",
    "print(\"Test precision:{:.10f}%\".format(test_precision * 100))\n",
    "test_recall = recall_score(test_lb_combined, test_pdlb_combined)\n",
    "print(\"Test recall:{:.10f}%\".format(test_recall * 100))\n",
    "test_confu_matrix = confusion_matrix(test_lb_combined,test_pdlb_combined)\n",
    "print(\"Test confusion matrix is:\")\n",
    "print(test_confu_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
